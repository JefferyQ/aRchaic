---
title: "How to generate a Mismatch Feature Format file?"
date: "1/5/2018"
output: html_document
---

The first step in the aRchaic workflow involves generating a *Mismatch Feature Format (MFF)* file from a given BAM file and the reference genome FASTA file. The steps are 
demonstrated as follows.

## Generating Mismatch Feature Format (MFF) file

First index the BAM file using [samtools](http://samtools.sourceforge.net/). 

```{bash, eval=FALSE}
samtools index example.bam
```

Export the path to the `generate_summary_bams.py` Python script to the $PATH variable and then run the following command.

```{bash, eval=FALSE}
python generate_summary_bams.py -b example.bam -f example.fa -o example.csv 
```

The reference genome (*example.fa*) needs to be 2009 assembly of the human genome (hg19, GRCh37 Genome Reference Consortium Human Reference 37). This file can be obtained from
[here](http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.gz).

Some versions of the hg19 fasta file contain the `chr` prefix to indicate the chromosome in the contig names, while others do not. In case the prefix is absent, use the `--add-chr` option as shown below.

```{bash, eval=FALSE}
python generate_summary_bams.py -b example.bam -f example.fa -o example.csv --add-chr
```

The full documentation of the `generate_summary_bams.py` function is provided below.

```{bash, echo=TRUE, eval=FALSE}
python --help generate_summary_bams.py
```


```
usage: python [option] ... [-c cmd | -m mod | file | -] [arg] ...
Options and arguments (and corresponding environment variables):
-b     : issue warnings about str(bytes_instance), str(bytearray_instance)
         and comparing bytes/bytearray with str. (-bb: issue errors)
-B     : don't write .py[co] files on import; also PYTHONDONTWRITEBYTECODE=x
-c cmd : program passed in as string (terminates option list)
-d     : debug output from parser; also PYTHONDEBUG=x
-E     : ignore PYTHON* environment variables (such as PYTHONPATH)
-h     : print this help message and exit (also --help)
-i     : inspect interactively after running script; forces a prompt even
         if stdin does not appear to be a terminal; also PYTHONINSPECT=x
-I     : isolate Python from the user's environment (implies -E and -s)
-m mod : run library module as a script (terminates option list)
-O     : optimize generated bytecode slightly; also PYTHONOPTIMIZE=x
-OO    : remove doc-strings in addition to the -O optimizations
-q     : don't print version and copyright messages on interactive startup
-s     : don't add user site directory to sys.path; also PYTHONNOUSERSITE
-S     : don't imply 'import site' on initialization
-u     : unbuffered binary stdout and stderr, stdin always buffered;
         also PYTHONUNBUFFERED=x
         see man page for details on internal buffering relating to '-u'
-v     : verbose (trace import statements); also PYTHONVERBOSE=x
         can be supplied multiple times to increase verbosity
-V     : print the Python version number and exit (also --version)
         when given twice, print more information about the build
-W arg : warning control; arg is action:message:category:module:lineno
         also PYTHONWARNINGS=arg
-x     : skip first line of source, allowing use of non-Unix forms of #!cmd
-X opt : set implementation-specific option
file   : program read from script file
-      : program read from stdin (default; interactive mode if a tty)
arg ...: arguments passed to program in sys.argv[1:]

Other environment variables:
PYTHONSTARTUP: file executed on interactive startup (no default)
PYTHONPATH   : ':'-separated list of directories prefixed to the
               default module search path.  The result is sys.path.
PYTHONHOME   : alternate <prefix> directory (or <prefix>:<exec_prefix>).
               The default module search path uses <prefix>/pythonX.X.
PYTHONCASEOK : ignore case in 'import' statements (Windows).
PYTHONIOENCODING: Encoding[:errors] used for stdin/stdout/stderr.
PYTHONFAULTHANDLER: dump the Python traceback on fatal errors.
PYTHONHASHSEED: if this variable is set to 'random', a random value is used
   to seed the hashes of str, bytes and datetime objects.  It can also be
   set to an integer in the range [0,4294967295] to get hash values with a
   predictable seed.
PYTHONMALLOC: set the Python memory allocators and/or install debug hooks
   on Python memory allocators. Use PYTHONMALLOC=debug to install debug
   hooks.

```

## Structure of an MFF file

An MFF file looks as follows 

```{bash, eval=FALSE}
head example.csv
```


```
CC->TA,82,10,T,C,-,1
CC->TT,87,5,T,C,-,1
CT->AA,88,4,T,C,-,1
AA->CC,90,2,T,C,-,1
CC->TC,28,53,C,C,-,2
CC->TA,40,47,A,C,-,3
CC->TT,69,18,A,C,-,3
AC->AC,79,8,A,C,-,3
AC->AC,68,25,T,C,-,4
CT->AA,78,15,T,C,-,4
```

It is a comma-separated csv file comprising of 7 columns.

- *1st column* : (flanking base 5' to mismatch)(mismatch)(flanking base 3' to mismatch). Example:  (C)(C->T)(A) for the first line of the MFF file.

- *2nd, 3rd columns* : distance of the mismatch from the two ends of the strand. 

- *4th, 5th columns* : base immediately next to the read end at the two ends of the read. One of the ends will match with strand break for an aDNA sample. 

- *6th column* : The orientation of the strand (+ : 5' to 3' , - : 3' to 5' strand)

- *7th column* : The number of mismatches observed with the features listed in the first 6 columns.



## Installation

```{r}
library(aRchaic)
```

## Logo representation of an MFF file

```{r echo=TRUE, eval=FALSE}
aRchaic_view(file = "../data/Skoglund/Gok4.hs37d5.fa.merged.q30.csv",
             output_dir = "../output/",
             filename = "logo_Gok4_Skoglund")
```

This logo plot requires performing a feature aggregation step and then computing the relative frequencies of each of these features. When several MFF files are stored in a folder, one can perform a pooled feature aggregation step for all the files in the folder, using the function `aRchaic_pool()`.

## Summarizing multiple MFF files 

```{r eval = FALSE}
out <- aRchaic_pool(folders = "../data/Skoglund/")
```

This function creates a .RData file *Skoglund.rda* in **../data/Skoglund/**. This object is a data matrix with the number of rows equal to the number of sample MFF files in the folder and the number of columns equal to the number of distinct signatures or aggregated features from the first 6 columns of the MFF file - for example an example column name could be AC->AA_-_A_1 - indicating a C->A mismatch flanked by A's on both sides and occurring in the first position from 5' end of a read obtained from a - strand with an A base at the position immediately preceding the strand break. The data in the matrix corresponds to the 7th column of the MFF file, recording the count of how many times a signature such as the one above would occur in each sample MFF file.

If the *.rda* file is present in a folder, the `aRchaic_view()` function would skip the feature aggregation step and generate the logo plot directly from the data in the *.rda* file. 

```{r eval= FALSE}
base_probs_list <- get(load("../output/base_probs_temp_2.rda"))
aRchaic_view(file = "../data/Skoglund/Gok4.hs37d5.fa.merged.q30.csv",
             output_dir = "../output/",
             logo.control = list(base_probs_list = base_probs_list),
             filename = "logo_Gok4_Skoglund_2")
```
## Clustering and Visualization 

We apply the Grade of Membership clustering model on multiple MFF files, possibly from different studies. 

In the first example, we run our model on the MFF files from only one study, stored in 
**../data/Skoglund/**

```{r eval=FALSE}
labs <- c(rep("Skoglund",5))
clus <- aRchaic_cluster(folders = c("../data/Skoglund/"),
                K = 2, 
                tol = 1,
                labs = labs,
                run_from = "gom",
                output_dir = "../output/skoglund_2/")
```

The outputs from this function will be saved in the *output_dir*. The outputs include 

- a **model.rda** file that stores all the estimates from the fitted Grade of Membership (GoM) model.

- a **structure.png** file that stores the STRUCTURE plot representation of the grades of membership from the fitted model, blocked by the labels.

- Logo representation of each cluster *k*, *logo_clus_k.png*, displaying the mismatch feature probabilities for the cluster.

We now present a second example, where we pool in data from two different studies - one modern study (subset of 1000 Genomes) saved in the folder *../data/moderns-50* and the aDNA example data folder from above.

```{r eval=FALSE}
labs <- c(rep("Skoglund",5), rep("moderns-50",50))
clus <- aRchaic_cluster(folders = c("../data/Skoglund/", "../data/moderns-50/"),
                K = 2, 
                tol = 1,
                labs = labs,
                run_from = "gom",
                output_dir = "../output/skoglund_moderns_2/")
```

The logo representation plots enrichment of each of the mismatch features compared to a background, which under the default, assumes equal probability for all possible signatures. Alternatively, an user can use a modern background. An example of that is illustrated below.

```{r eval=FALSE}
labs <- c(rep("Skoglund",5), rep("moderns-50",50))
base_probs_list <- get(load("../output/base_probs_temp_2.rda"))

clus <- aRchaic_cluster(folders = c("../data/Skoglund/", "../data/moderns-50/"),
                K = 2, 
                tol = 1,
                labs = labs,
                run_from = "gom",
                logo.control = list(base_probs_list = base_probs_list,
                                    mut_ranges = c(1,1.5),
                                    break_ranges = c(0.5,0.5)),
                output_dir = "../output/skoglund_moderns_2_background/")
```

Note that `mut_ranges` and `break_ranges` options are used to maintain same scale of the Y axes for the mismatch EDLogo and the strand break EDLogo plots across different clusters. When not specified, optimal Y axes scaling is performed separately for each cluster and for each EDLogo plot and hence may vary between clusters.

*aRchaic_cluster()* provides an input argument `run_from` that allows the user to select which steps to perform while re-running the model and visualization on the same example. The three possible options for `run_from` input are `start`, `gom` and `plot`.

When `run_from = start`, the function starts from scratch, builds the aggregated MFF file (.rda) from the MFF csv files in each inuput directory listed in `folders` using `aRchaic_pool()`. Then it pools the aggregated MFF files from all the listed input directories, merges them and then runs the GoM model and saves the results. 

When `run_from = gom`, the function first checks if the aggregated MFF file (denoted by .rda) is present in each of the input directories in the `folders` input argument. Only when the *.rda* file is not present in one of the folders, then the function would generate it. The rest of the steps are similar to the `run_from = start` option.

When `run_from = plot`, the function checks if the `model.rda` file is present in the output directory. If present, it just runs the visualization functions on the saved `model.rda` file. If the file is not present, the  it switches to `run_from = gom`, runs the model and creates the `model.rda` file in the output directory along with the relevant visualization. 

## Principal Component Analysis

Besides the GoM model fit, aRchaic also allows the user to perform dimension reduction and visualization using PCA.

```{r eval=TRUE}
labs <- c(rep("Skoglund",6), rep("moderns-50",50))
library(gridExtra)
clus <- aRchaic_pca(folders = c("../data/Skoglund/", "../data/moderns-50/"),
                labs = labs,
                run_from = "plot",
                pcs_to_plot = c("PC1", "PC2", "PC3"),
                output_dir = "../output/skoglund_moderns_2_background/")
```

This creates a **pca.png** file storing the PCA results for the first three PCs in the **output_dir**.

```{r}
read_length_distribution(file = "../data/Skoglund/Ajv52.hs37d5.fa.merged.q30.csv")
```

```{r}
topic_clus <- get(load("../output/skoglund_moderns_2/model.rda"))
theta_breakdown(theta_pool = topic_clus$theta)
```

